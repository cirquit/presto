{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artificial Type Dataset Profiling\n",
    "\n",
    "### Prerequisites\n",
    "\n",
    "None. Exemplary logs are loaded by default. Experiments were run on:\n",
    "\n",
    "* Storage: CEPH HDDs\n",
    "* CPU: Intel Xeon E5-2630 v3 8x@2.4GHz\n",
    "* Image: ubuntu-18.04-lts/Openstack\n",
    "* Memory: 80GB DDR4\n",
    "\n",
    "The dataset is defined to be 15GB.\n",
    "\n",
    "The sample count varies to showcase differences in performance with the same amount of data.\n",
    "\n",
    "Every experiment was done 5 times, with two datatypes: `uint8` and `float32`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import re\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pylab as plt\n",
    "from matplotlib import ticker\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "from typing import List\n",
    "# adding previous directory for easier use of library\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "from notebookhelper import show_values_on_bars, show_values_on_catplot, save_figure, make_big_number_prettier \\\n",
    "                         , make_big_number_prettier_storage_mb\n",
    "\n",
    "from presto.analysis import StrategyAnalysis \\\n",
    "                       , strat_analysis_from_csv\n",
    "\n",
    "pd.set_option('display.max_rows', 200)\n",
    "plotting_context = \"paper\"\n",
    "default_palette = \"colorblind\"\n",
    "epoch_palette = sns.color_palette(\"YlOrRd\", 3)\n",
    "samples_palette = sns.color_palette(\"icefire\", 15)\n",
    "threads_palette = sns.color_palette(\"tab20\", 4)\n",
    "font_scale = 1.4\n",
    "sns.set(font_scale=font_scale, context=plotting_context)\n",
    "sns.set(rc={\"figure.dpi\":300, 'savefig.dpi':300})\n",
    "\n",
    "local_fig_dir = \"misc\"\n",
    "\n",
    "def save_fig(name, file_type='pdf'):\n",
    "    save_figure(name, local_fig_dir=local_fig_dir, file_type=file_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### X.1 Calculation on how many samples we need for differing sample storage consumptions\n",
    "\n",
    "Calculating the float32 ones, as we want the sample counts to be natural numbers.\n",
    "\n",
    "To calculate the uint8 sample counts, we need to multiply the the float32 ones times 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vector_lines</th>\n",
       "      <th>vector_lines_uint8</th>\n",
       "      <th>sample_storage_consumption_mb</th>\n",
       "      <th>sample_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0.02</td>\n",
       "      <td>750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>0.04</td>\n",
       "      <td>375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>0.08</td>\n",
       "      <td>187500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16</td>\n",
       "      <td>64</td>\n",
       "      <td>0.16</td>\n",
       "      <td>93750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>32</td>\n",
       "      <td>128</td>\n",
       "      <td>0.32</td>\n",
       "      <td>46875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>64</td>\n",
       "      <td>256</td>\n",
       "      <td>0.64</td>\n",
       "      <td>23437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>128</td>\n",
       "      <td>512</td>\n",
       "      <td>1.28</td>\n",
       "      <td>11718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>256</td>\n",
       "      <td>1024</td>\n",
       "      <td>2.56</td>\n",
       "      <td>5859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>512</td>\n",
       "      <td>2048</td>\n",
       "      <td>5.12</td>\n",
       "      <td>2929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1024</td>\n",
       "      <td>4096</td>\n",
       "      <td>10.24</td>\n",
       "      <td>1464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2048</td>\n",
       "      <td>8192</td>\n",
       "      <td>20.48</td>\n",
       "      <td>732</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    vector_lines  vector_lines_uint8  sample_storage_consumption_mb  \\\n",
       "0              1                   4                           0.01   \n",
       "1              2                   8                           0.02   \n",
       "2              4                  16                           0.04   \n",
       "3              8                  32                           0.08   \n",
       "4             16                  64                           0.16   \n",
       "5             32                 128                           0.32   \n",
       "6             64                 256                           0.64   \n",
       "7            128                 512                           1.28   \n",
       "8            256                1024                           2.56   \n",
       "9            512                2048                           5.12   \n",
       "10          1024                4096                          10.24   \n",
       "11          2048                8192                          20.48   \n",
       "\n",
       "    sample_count  \n",
       "0        1500000  \n",
       "1         750000  \n",
       "2         375000  \n",
       "3         187500  \n",
       "4          93750  \n",
       "5          46875  \n",
       "6          23437  \n",
       "7          11718  \n",
       "8           5859  \n",
       "9           2929  \n",
       "10          1464  \n",
       "11           732  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_vector = 2500 # defined in the type_demo.py\n",
    "float32_in_mb = 4 / 1000**2 # 32bit -> 4 byte\n",
    "min_sample_size_mb = base_vector * float32_in_mb # smallest possible sample storage consumption\n",
    "max_dataset_size_mb = 15 * 1000.0 # maximum total storage consumption in MB\n",
    "\n",
    "sample_dict = {\n",
    "    \"vector_lines\": [],\n",
    "    \"vector_lines_uint8\": [],\n",
    "    \"sample_storage_consumption_mb\": [],\n",
    "    \"sample_count\": []\n",
    "}\n",
    "\n",
    "for count in range(0,12):\n",
    "    \n",
    "    vector_lines = 2**count\n",
    "    sample_storage_consumption_mb = min_sample_size_mb * vector_lines\n",
    "    sample_count = int(max_dataset_size_mb / sample_storage_consumption_mb)\n",
    "    \n",
    "    sample_dict[\"vector_lines\"].append(vector_lines)\n",
    "    sample_dict[\"vector_lines_uint8\"].append(vector_lines * 4)\n",
    "    sample_dict[\"sample_storage_consumption_mb\"].append(sample_storage_consumption_mb)\n",
    "    sample_dict[\"sample_count\"].append(sample_count)\n",
    "\n",
    "pd.DataFrame(sample_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### X.2 Some helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_datatype_log(path_to_cum_df, path_to_cum_dstat_df, datatype):\n",
    "    '''Filter the type cumulative dataframes\n",
    "    For easier evaluation, we drop the unnecessary columns.\n",
    "    '''\n",
    "    analysis = strat_analysis_from_csv(path_to_cum_dstat_df = path_to_cum_dstat_df\n",
    "                                     , path_to_cum_df = path_to_cum_df)\n",
    "    cum_dstat_df = analysis.to_cum_dstat_df()\n",
    "    cum_df       = analysis.to_cum_df()\n",
    "    # need to sort the strategies for some reason as they are not ascending\n",
    "    cum_df = cum_df.sort_values(by='split_name')\n",
    "    strategies   = list(cum_df.split_name.unique())\n",
    "    # add the average storage consumption per sample\n",
    "    cum_df[\"per_sample_size_MB\"] = cum_df[\"shard_cum_size_MB\"] / cum_df[\"sample_count\"]\n",
    "    # add the datatype as column to each df\n",
    "    cum_df[\"dtype\"] = datatype\n",
    "    cum_dstat_df[\"dtype\"] = datatype\n",
    "    \n",
    "    # delete not needed columns\n",
    "    cum_df = cum_df.drop('shard_count', 1)\n",
    "    cum_df = cum_df.drop('thread_count', 1)\n",
    "    #cum_df = cum_df.drop('runs_count', 1)\n",
    "    #cum_df = cum_df.drop('runs_total', 1)\n",
    "    cum_df = cum_df.drop('compression_type', 1)\n",
    "    cum_df = cum_df.drop('storage_type', 1)\n",
    "    cum_df = cum_df.drop('throughput_sps', 1)\n",
    "    cum_df = cum_df.drop('split_name', 1)\n",
    "    \n",
    "    cum_dstat_df = cum_dstat_df.drop('shard_count', 1)\n",
    "    cum_dstat_df = cum_dstat_df.drop('thread_count', 1)\n",
    "    #cum_dstat_df = cum_dstat_df.drop('run', 1)\n",
    "    cum_dstat_df = cum_dstat_df.drop('compression_type', 1)\n",
    "    cum_dstat_df = cum_dstat_df.drop('storage_type', 1)\n",
    "    \n",
    "    return cum_df, cum_dstat_df\n",
    "\n",
    "def extract_online_processing_frames(sample_count, df, dstat_df):\n",
    "    '''Extracts the online processing time from the dataframe.\n",
    "    Filters the dstat_df by that online processing time.\n",
    "    '''        \n",
    "    max_offline_processing_time_s = df.query(\n",
    "        f\"sample_count=={sample_count}\")[\"offline_processing_and_save_time_s\"].max()\n",
    "    \n",
    "    filtered_dstat_df = dstat_df.query(\n",
    "        f\"sample_count=='{sample_count}' and rel_time_s>={max_offline_processing_time_s}\")\n",
    "    \n",
    "    return filtered_dstat_df\n",
    "\n",
    "\n",
    "def return_online_df(df, dstat_df):\n",
    "    '''Returns the dstat dataframe filteredy by online processing time\n",
    "    Also prints a summary about the network reads\n",
    "    '''\n",
    "    sample_counts = df.sample_count.unique()\n",
    "    frames = [extract_online_processing_frames(sample_count=sample_count\n",
    "                                              ,df=df\n",
    "                                              ,dstat_df=dstat_df) for sample_count in sample_counts]\n",
    "    online_dstat_df = pd.concat(frames)\n",
    "    \n",
    "    for sample_count in np.sort(df.sample_count.unique()):\n",
    "    \n",
    "        avg_online_processing_time = df.query(\n",
    "            f\"sample_count=={sample_count}\")[\"online_processing_time_s\"].describe().iloc[1]\n",
    "    \n",
    "    \n",
    "        print(\"---------------------------------------\")\n",
    "        print(f\"-- {sample_count} Network Read in MB/s --\")\n",
    "        print(f\"-- {sample_count} Online Processing time: {int(avg_online_processing_time)}\")\n",
    "    \n",
    "        temp_df = online_dstat_df.query(f\"sample_count=='{sample_count}'\")\n",
    "        print(temp_df.describe()[\"net_read_mbs\"])\n",
    "\n",
    "    return online_dstat_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Logs"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "log_path = \"/logs\"\n",
    "uint8_path = f\"{log_path}/uint8\"\n",
    "float32_path = f\"{log_path}/float32\"\n",
    "\n",
    "path_to_uint8_cum_df = f\"{uint8_path}/full-log_cum-df.csv\"\n",
    "path_to_uint8_cum_dstat_df = f\"{uint8_path}/full-log_cum-dstat-df.csv\"\n",
    "path_to_float32_cum_df = f\"{float32_path}/full-log_cum-df.csv\"\n",
    "path_to_float32_cum_dstat_df = f\"{float32_path}/full-log_cum-dstat-df.csv\"\n",
    "\n",
    "uint8_dtype = \"uint8\"\n",
    "float32_dtype = \"float32\"\n",
    "\n",
    "cum_uint8_sys_df, cum_uint8_sys_dstat_df = read_datatype_log(path_to_cum_df = path_to_uint8_cum_df\n",
    "                                                   , path_to_cum_dstat_df = path_to_uint8_cum_dstat_df\n",
    "                                                   , datatype = uint8_dtype )\n",
    "cum_float32_sys_df, cum_float32_sys_dstat_df = read_datatype_log(path_to_cum_df = path_to_float32_cum_df\n",
    "                                                   , path_to_cum_dstat_df = path_to_float32_cum_dstat_df\n",
    "                                                   , datatype = float32_dtype )\n",
    "strategies_renamed = [\"read-dataset\"]\n",
    "cum_summary_df = pd.concat([cum_uint8_sys_df, cum_float32_sys_df])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "cum_float32_sys_df.query(\"runs_count==0\").sort_values(by=\"sample_count\").groupby(by=\"sample_count\").mean()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "throughput_20mb = cum_float32_sys_df.query(\"runs_count==0 and sample_count==732\").mean()[\"online_processing_time_s\"]\n",
    "throughput_001mb = cum_float32_sys_df.query(\"runs_count==0 and sample_count==1500000\").mean()[\"online_processing_time_s\"]\n",
    "factor = throughput_001mb / throughput_20mb\n",
    "print(f\"> 20MB faster than 0.01MB by {factor}\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "cum_uint8_sys_df.query(\"runs_count==0\").sort_values(by=\"sample_count\").groupby(by=\"sample_count\").mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Online processing time for `uint8` and `float32` for epoch 0"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "samples_palette = sns.color_palette(\"icefire\", 1)\n",
    "sns.set(palette=samples_palette, font_scale=0.6)\n",
    "\n",
    "storage_consumption_per_samples = list(cum_summary_df.query(\"runs_count==0\") \\\n",
    "                                                    .groupby(by='sample_count') \\\n",
    "                                                    .mean()[\"per_sample_size_MB\"].round(2))\n",
    "storage_consumption_per_samples.sort(reverse=True)\n",
    "def custom_format(label):\n",
    "    if label > 0.9:\n",
    "        return str(round(label,1))\n",
    "    else:\n",
    "        return str(label)\n",
    "sc_per_samples_labels = [custom_format(label) for label in storage_consumption_per_samples]\n",
    " \n",
    "    \n",
    "plt.figure(figsize=(4.5,1))\n",
    "plot = sns.barplot(\n",
    "    x=\"sample_count\"\n",
    "   ,y=\"online_processing_time_s\"\n",
    "   ,hue=\"dtype\"\n",
    "   ,data=cum_summary_df.query(\"runs_count==0\"))\n",
    "\n",
    "plot.set_xticklabels(\n",
    "    sc_per_samples_labels\n",
    "  , rotation=10\n",
    ")\n",
    "plot.tick_params(axis='x', which='major', pad=-2.5)\n",
    "plot.tick_params(axis='y', which='major', pad=-2.5)\n",
    "plot.set(xlabel=\"Storage Consumption per Sample in MB\", ylabel=\"Total Online\\n Processing Time\\n in Seconds\")\n",
    "plot.set(ylim=(0, 190))\n",
    "#show_values_on_bars(plot, h_v=\"v\", space=10, rotation=15)\n",
    "plot.legend(title=\"DType\", ncol=1, labelspacing=0.1)\n",
    "save_fig(\"artificial-dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Application Caching Logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_path = \"/logs\"\n",
    "float32_sys_caching_path = f\"{log_path}/float32/sys-caching\"\n",
    "float32_app_caching_path = f\"{log_path}/float32/app-caching\"\n",
    "\n",
    "path_to_float32_sys_cum_df = f\"{float32_sys_caching_path}/full-log_cum-df.csv\"\n",
    "path_to_float32_sys_cum_dstat_df = f\"{float32_sys_caching_path}/full-log_cum-dstat-df.csv\"\n",
    "path_to_float32_app_cum_df = f\"{float32_app_caching_path}/full-log_cum-df.csv\"\n",
    "path_to_float32_app_cum_dstat_df = f\"{float32_app_caching_path}/full-log_cum-dstat-df.csv\"\n",
    "\n",
    "float32_dtype = \"float32\"\n",
    "\n",
    "cum_float32_sys_df, cum_float32_sys_dstat_df = read_datatype_log(\n",
    "                                                     path_to_cum_df = path_to_float32_sys_cum_df\n",
    "                                                   , path_to_cum_dstat_df = path_to_float32_sys_cum_dstat_df\n",
    "                                                   , datatype = float32_dtype )\n",
    "\n",
    "cum_float32_app_df, cum_float32_app_dstat_df = read_datatype_log(\n",
    "                                                     path_to_cum_df = path_to_float32_app_cum_df\n",
    "                                                   , path_to_cum_dstat_df = path_to_float32_app_cum_dstat_df\n",
    "                                                   , datatype = float32_dtype )\n",
    "strategies_renamed = [\"read-dataset\"]\n",
    "cum_float32_app_df = cum_float32_app_df.sort_values(by=[\"sample_count\"])\n",
    "cum_float32_app_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Summary Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = \"cache_type\"\n",
    "\n",
    "no_cache_df = cum_float32_sys_df.query(\"runs_count==0\").copy(deep=True)\n",
    "no_cache_df[key] = \"0-no-cache\"\n",
    "sys_cache_df = cum_float32_sys_df.query(\"runs_count==1\").copy(deep=True)\n",
    "sys_cache_df[key] = \"1-sys-cache\"\n",
    "app_cache_df = cum_float32_app_df.query(\"runs_count==0\") # the initial run is already cached due to presto's evaluation\n",
    "app_cache_df[key] = \"2-app-cache\"\n",
    "\n",
    "full_comparison_df = pd.concat([app_cache_df, sys_cache_df, no_cache_df])\n",
    "full_comparison_df = full_comparison_df.sort_values(by=[\"sample_count\", key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from notebookhelper import show_values_on_bars\n",
    "\n",
    "sns.set(palette=epoch_palette, font_scale=0.6)\n",
    "\n",
    "storage_consumption_per_samples = list(full_comparison_df.query(\"runs_count==0\") \\\n",
    "                                                    .groupby(by='sample_count') \\\n",
    "                                                    .mean()[\"per_sample_size_MB\"].round(2))\n",
    "storage_consumption_per_samples.sort(reverse=True)\n",
    "def custom_format(label):\n",
    "    if label > 0.9:\n",
    "        return str(round(label,1))\n",
    "    else:\n",
    "        return str(label)\n",
    "sc_per_samples_labels = [custom_format(label) for label in storage_consumption_per_samples]\n",
    "\n",
    "plt.figure(figsize=(4.5,2))\n",
    "\n",
    "plot = sns.barplot(\n",
    "    x=\"sample_count\"\n",
    "   ,y=\"online_processing_time_s\"\n",
    "   ,hue=key\n",
    "   ,data=full_comparison_df)\n",
    "\n",
    "plot.set_xticklabels(\n",
    "    sc_per_samples_labels\n",
    "  , rotation=10\n",
    ")\n",
    "plot.tick_params(axis='x', which='major', pad=-2.5)\n",
    "plot.tick_params(axis='y', which='major', pad=-2.5)\n",
    "#plot.set(ylim=(0, 220))\n",
    "legend = plot.legend(title=\"Caching Level\", ncol=1, labelspacing=0.1)#, loc=(0.2,0.7))\n",
    "legend.get_texts()[0].set_text('no-cache')\n",
    "legend.get_texts()[1].set_text('sys-cache')\n",
    "legend.get_texts()[2].set_text('app-cache')\n",
    "plot.set(xlabel=\"Storage Consumption per Sample in MB\", ylabel=\"Total Online Processing Time\\n in Seconds\")\n",
    "show_values_on_bars(plot, h_v=\"v\", space=20, rotation=90, fontsize=6, round_to=1, allowed_index=[24,25,26,27,28,29,30,31,32,33,34,35],\n",
    "                               additional_x_space=[0,0,0,0,0,0,0,0,0,0,0,0\n",
    "                                                  ,0,0,0,0,0,0,0,0,0,0,0,0\n",
    "                                                  ,+0.1,+0.1,+0.1,+0.1,+0.1,+0.1,+0.1,+0.1,+0.1,+0.1,+0.1,0],\n",
    "                               additional_space=[0,0,0,0,0,0,0,0,0,0,0,0\n",
    "                                                  ,0,0,0,0,0,0,0,0,0,0,0,0\n",
    "                                                  ,0,0,0,0,0,0,0,0,5,5,10,20])\n",
    "show_values_on_bars(plot, h_v=\"v\", space=30, rotation=90, fontsize=6, round_to=1, allowed_index=[12,13,14,15,16,17,18,19,20,21,22,23],\n",
    "                                                   additional_x_space=[0,0,0,0,0,0,0,0,0,0,0,0\n",
    "                                                  ,+0.05,+0.05,+0.05,+0.05,+0.05,0.05,0.05,0.05,0.05,0.05,0,0,0,0,0,0,0\n",
    "                                                  ,0,0,0,0,0,0,0]\n",
    "                    ,additional_space=[0,0,0,0,0,0,0,0,0,0,0,0\n",
    "                                      ,0,0,0,0,0,0,0,0,0,0,0,5\n",
    "                                      ,0,0,0,0,0,0,0,0,0,0,0,0])\n",
    "show_values_on_bars(plot, h_v=\"v\", space=30, rotation=90, fontsize=6, round_to=1, allowed_index=[0,1,2,3,4,5,6,7,8,9,10,11]\n",
    "                    ,additional_space=[0,0,0,0,0,0,0,0,0,0,0,5\n",
    "                                      ,0,0,0,0,0,0,0,0,0,0,0,0\n",
    "                                      ,0,0,0,0,0,0,0,0,0,0,0,0])\n",
    "                               #additional_x_space=[0,0,0,0,0,0,0,0,0,0,0,0\n",
    "                               #                   ,0,0,0,0,0,0,0,0,0,0,0,0\n",
    "                               #                   ,+0.05,+0.05,+0.05,+0.05,+0.05,0,0,0,0,0,0,0])\n",
    "save_fig(\"synthetic-dataset-all-caches\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
