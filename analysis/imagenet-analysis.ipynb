{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imagenet Pipeline Profiling Analysis\n",
    "\n",
    "### Prerequisites\n",
    "\n",
    "None. Exemplary logs are loaded by default. Experiments were run on:\n",
    "\n",
    "* Storage: CEPH HDD\n",
    "* CPU: Intel Xeon E5-2630 v3 8x@2.4GHz\n",
    "* Image: ubuntu-18.04-lts/Openstack\n",
    "* Memory: 80GB DDR4\n",
    "\n",
    "All plots that are not saved with the `save_fig` function were not used in the paper, but may provide a close-up look on specific values.\n",
    "\n",
    "### Meta information\n",
    "\n",
    "* \"first\" preprocessing step of listing the files was removed (check `imagenet_demo.py`) because it did not affect performance in our tests. This should be reintroduced when simulating distributed training, e.g., federated learning, where getting the file locations can actually affect performance\n",
    "\n",
    "* Dataset size: `146.899991342 GB` (`imagenet/ILSVRC/Data/CLS-LOC/train> du -hb .` / 1000 / 1000)\n",
    "* Amount of `.JPEG` files: `1281167` (`imagenet/ILSVRC/Data/CLS-LOC/train> find . -name \"*.JPEG\" | wc -l`)\n",
    "* Avg. filesize: `0.11466107957978935 MB`\n",
    "* Avg. resolution (Imagenet paper): `400x350`\n",
    "* Sample sizes (rounded to second decimal):\n",
    "    * `   0500:        57.33 MB` \n",
    "    * `   1000:       114.66 MB`\n",
    "    * `   2000:       229.32 MB`\n",
    "    * `   4000:       458.64 MB`\n",
    "    * `   8000:       917.29 MB`\n",
    "    * `1281167: 146899.99 MB` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500 of total: 0.04%\n",
      "1000 of total: 0.08%\n",
      "2000 of total: 0.16%\n",
      "4000 of total: 0.31%\n",
      "8000 of total: 0.62%\n"
     ]
    }
   ],
   "source": [
    "full_dataset_samplecount = 1281167\n",
    "#for sample_size in [500, 1000, 2000, 4000, 8000]:\n",
    "#    print(f\"{sample_size} of total: {round(sample_size / full_dataset_samplecount * 100, 2)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import re\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pylab as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib import ticker\n",
    "from typing import List\n",
    "# adding previous directory for easier use of library\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "from notebookhelper import show_values_on_bars, show_values_on_catplot, save_figure, make_big_number_prettier \\\n",
    "                         , make_big_number_prettier_storage_mb\n",
    "\n",
    "from presto.analysis import StrategyAnalysis \\\n",
    "                       , strat_analysis_from_csv\n",
    "\n",
    "pd.set_option('display.max_rows', 200)\n",
    "plotting_context = \"paper\"\n",
    "default_palette = \"colorblind\"\n",
    "epoch_palette = sns.color_palette(\"YlOrRd\", 3)\n",
    "samples_palette = sns.color_palette(\"icefire\", 15)\n",
    "threads_palette = sns.color_palette(\"tab20\", 4)\n",
    "font_scale = 1.4\n",
    "sns.set(font_scale=font_scale, context=plotting_context)\n",
    "sns.set(rc={\"figure.dpi\":300, 'savefig.dpi':300})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_fig_dir = \"imagenet-pipeline\"\n",
    "\n",
    "def save_fig(name, file_type='pdf'):\n",
    "    save_figure(name, local_fig_dir=local_fig_dir, file_type=file_type)\n",
    "    \n",
    "    \n",
    "log_path = \"/logs/\"\n",
    "path_to_cum_df = f\"{log_path}/full-log_cum-df.csv\"\n",
    "path_to_cum_dstat_df = f\"{log_path}/full-log_cum-dstat-df.csv\"\n",
    "sampling_tag = \"\"\n",
    "\n",
    "analysis = strat_analysis_from_csv(path_to_cum_dstat_df = path_to_cum_dstat_df\n",
    "                                   , path_to_cum_df = path_to_cum_df)\n",
    "cum_dstat_df = analysis.to_cum_dstat_df()\n",
    "cum_df       = analysis.to_cum_df()\n",
    "# need to sort the strategies for some reason as they are not ascending\n",
    "cum_df = cum_df.sort_values(by='split_name')\n",
    "strategies   = list(cum_df.split_name.unique())\n",
    "strategies_renamed = [\"unprocessed\", \"concatenated\", \"decoded\", \"resized\", \"pixel-\\ncentered\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Storage Consumption vs Throughput Tradeoffs\n",
    "### Full dataset, 8 threads, epoch 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_sample_count = 500\n",
    "\n",
    "cum_df_temp = cum_df.query(f\"sample_count=={local_sample_count} \\\n",
    "                         and thread_count==8 \\\n",
    "                         and runs_count==0\")\n",
    "\n",
    "sample_size_mb_dict = {\n",
    "    \"500\": 58.42\n",
    "  , \"1000\": 116.84\n",
    "  , \"2000\": 233.68\n",
    "  , \"4000\": 467.35\n",
    "  , \"8000\": 934.71\n",
    "  , f\"{full_dataset_samplecount}\": 146899.991342\n",
    "}\n",
    "\n",
    "storage_consumption_comparison = {\n",
    "    \"storage_consumption_mb\": []\n",
    "  , \"sample_count\": []\n",
    "  , \"strategy\": []\n",
    "}\n",
    "\n",
    "def add_to_dict(size, sample_count, label):\n",
    "    '''Short helper'''\n",
    "    storage_consumption_comparison[\"storage_consumption_mb\"] += [size]\n",
    "    storage_consumption_comparison[\"sample_count\"] += [sample_count]\n",
    "    storage_consumption_comparison[\"strategy\"] += [label]\n",
    "    \n",
    "for sample_count in cum_df_temp.sample_count.unique():\n",
    "    for i, strategy in enumerate(strategies):\n",
    "        shard_sizes_mb = cum_df_temp.query(f\"split_name=='{strategy}' and sample_count=={sample_count}\")[\"shard_cum_size_MB\"].to_numpy()\n",
    "        for size_mb in shard_sizes_mb:\n",
    "            if i == 0: # i.e., unprocessed\n",
    "                size_mb = sample_size_mb_dict[str(sample_count)]\n",
    "            add_to_dict(size = size_mb\n",
    "                      , sample_count = sample_count\n",
    "                      , label = strategies[i])\n",
    "\n",
    "storage_df = pd.DataFrame(storage_consumption_comparison)\n",
    "\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "sns.set(palette=default_palette, font_scale=0.9)\n",
    "throughput_color = \"#515151\"\n",
    "marker = 'o'\n",
    "linestyle = \":\"\n",
    "\n",
    "fig, ax1 = plt.subplots(figsize=(4.5,2))\n",
    "ax2 = ax1.twinx()\n",
    "\n",
    "# throughput plot\n",
    "plot2 = sns.pointplot(x=\"split_name\", y=\"throughput_sps\", data=cum_df_temp,\n",
    "                      ax=ax2, scale=0.75, color=throughput_color, linestyles=linestyle, ci=0.95, marker='o')\n",
    "\n",
    "plot2.set(ylabel=\"Throughput in Samples\\nper Second\")\n",
    "plot2.set_xticklabels(\n",
    "    strategies_renamed\n",
    "  , rotation=20\n",
    ")\n",
    "ax2.grid(False)\n",
    "legend_elements = [Line2D([0], [0], marker=marker, markersize=5, color=throughput_color, lw=2.5, label='Throughput', linestyle=linestyle)]\n",
    "ax2.legend(handles=legend_elements, loc=\"upper left\", prop={'size': 9})\n",
    "plot2.set(ylim=(0, 2300))\n",
    "\n",
    "plot = sns.barplot(\n",
    "        x=\"strategy\",\n",
    "        y=\"storage_consumption_mb\",\n",
    "        data=storage_df.query(f\"sample_count=={local_sample_count}\"),\n",
    "        ax=ax1\n",
    "    )\n",
    "plot.set_xticklabels(\n",
    "    strategies_renamed\n",
    "  , rotation=12\n",
    ")\n",
    "plot.tick_params(axis='x', which='major', pad=-1.5)\n",
    "show_values_on_bars(plot, h_v=\"v\", space=120000, rotation=5, additional_x_space=[0.05,0,0,0,0]\n",
    "                                                            , additional_space=[50000,0,0,0,0], storage_formatting=True)\n",
    "plot.set(ylabel=\"Storage Consumption\\nin MB\", xlabel=\"\")\n",
    "plot.set(ylim=(0, 1650000))\n",
    "\n",
    "plot.yaxis.set_major_formatter(make_big_number_prettier)\n",
    "plot2.yaxis.set_major_formatter(make_big_number_prettier)\n",
    "save_fig(\"storage-vs-throughput\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
